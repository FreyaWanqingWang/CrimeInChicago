//launch spark-shell
zhe_wang23@cluster-cd23-m:~$ spark-shell

//load csv file into spark and check fields name
scala> import org.apache.spark.sql.SQLContext
scala> val sqlContext = new SQLContext(sc)
scala> val df = sqlContext.read.format("com.databricks.spark.csv").option("header", "true").option("inferSchema", "true").load("hdfs:////user/crimedata/crime.csv")
scala> df.printSchema()

//delete fields containing null value
scala> df.limit(20).show
scala> var res = df.na.drop()
scala> res.limit(20).show

